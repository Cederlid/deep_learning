{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e1973",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cc8ba",
   "metadata": {},
   "source": [
    "## Överblick\n",
    "\n",
    "**Målet med dagens övning  modifiera våra neuroner samt träningsloop till att kunna lösa binära klassificeringsproblem.**\n",
    "\n",
    "Vi kommer skapa vår egen data mha scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ed956",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates, labels = make_blobs(n_samples=[500,500], \n",
    "                                 n_features=3, random_state=41)\n",
    "\n",
    "# visualisera de nyss skapade blobsen\n",
    "\n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(coordinates[:,0],\n",
    "             coordinates[:,1],\n",
    "             coordinates[:,2], \n",
    "             c=labels)\n",
    "\n",
    "ax.set_title(\"Class Divisions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ea45d",
   "metadata": {},
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f5f3e",
   "metadata": {},
   "source": [
    "## Dela upp data i train/test och utför nödvändiga transformationer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fae232",
   "metadata": {},
   "source": [
    "Som vi diskuterat behöver vi kunna uppskatta prestanda som kan förväntas uppnås i  en skarp, produktionssatt situation. Att enbart evaluera på träningsdata är därför inte lämpligt. Vi delar därför upp vårt dataset i en train- och en testsplit.\n",
    "\n",
    "Vi väljer att göra det i proportionen 90/10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b5437",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(coordinates,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35864e93",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49498825",
   "metadata": {},
   "source": [
    "**Skala data**\n",
    "\n",
    "Nu behöver vi på enklaste sätt bara skala om kolumnerna så att samtliga värden, till absolutbeloppet, inte blir särskilt mycket större än 1. Vi ser i vår illustrering ovan att så inte är fallet nu - utan att samtliga koordinater antar större värden än så.\n",
    "\n",
    "Ett supersimpelt trick för att åstadkomma detta är att helt enkelt dela respektive kolumn, med det (till absolutbeloppet) högsta värdet. Då kommer samtliga värden skalas ner, och det högsta värdet i respektive kolumn vara (i absolut värde) 1.\n",
    "\n",
    "**Kom dock ihåg att det är superviktigt att vi endast använder statistik från train split när vi transformerar, annars riskerar vi informationsläckage!**\n",
    "\n",
    "Detta var anledningen till att vi delade upp datasetet i train/test-split innan vi började med dessa invasiva ingrepp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in range(3):                               # iterera över alla vår tre coordinater\n",
    "    \n",
    "    highest_value = max(np.abs(x_train[:,i]))    # hitta det, till absolutbeloppet, högsta värdet i aktuella kolumn i x_train\n",
    "    \n",
    "    \n",
    "    # dela nu aktuell kolumn i x_train med det nyfunna högsta värdet\n",
    "    \n",
    "    x_train[:,i] = x_train[:,i] / highest_value \n",
    "    \n",
    "    # dela nu även motsvarande kolumn i x_test med SAMMA nyfunna högsta värde (från x_train)\n",
    "    \n",
    "    x_test[:,i] = x_test[:,i] / highest_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c2faa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c9ba5",
   "metadata": {},
   "source": [
    "Vi kan nu återigen visualisera vår data, som en sanity check. Lägg märke till skalan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e082ba9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(x_train[:,0],\n",
    "             x_train[:,1],\n",
    "             x_train[:,2], \n",
    "             c=y_train)\n",
    "\n",
    "ax.set_title(\"Train split\");\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(x_test[:,0],\n",
    "             x_test[:,1],\n",
    "             x_test[:,2], \n",
    "             c=y_test)\n",
    "\n",
    "ax.set_title(\"Test split\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a18541",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb59da0",
   "metadata": {},
   "source": [
    "**Omvandla till Tensor**\n",
    "\n",
    "Nu när siffrorna ser bra ut återstår det att omvandla till datatypen Tensor (optimal för PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.FloatTensor).reshape([-1,1])\n",
    "\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.FloatTensor).reshape([-1,1])\n",
    "\n",
    "training_set = list(zip(x_train, y_train))             # lägg ihop träningsdatan så att vi direkt kan skicka in i dataloader\n",
    "test_set = list(zip(x_test, y_test))                   # ditto för testdatan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959fe74",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e647f",
   "metadata": {},
   "source": [
    "## Skapa Neurons med Sigmoid-aktiveringsfunktion i PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3411a27",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc940ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class neuron(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(neuron, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)                  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bc182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "\n",
    "model = neuron(3)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0299f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5955c9c",
   "metadata": {},
   "source": [
    "**KONTROLLFRÅGA: hur många parametrar har den här modellen?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862b4e1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef532e",
   "metadata": {},
   "source": [
    "Låt oss testa vad vår, hitills otränade, modell spottar ut sig för output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 200                                     # välj här vilken sample som helst, ange värde mellan 0-899\n",
    "\n",
    "sample_features = x_train[sample]                # extrahera features\n",
    "sample_class = y_train[sample]                   # extrahera class (1 eller 0)\n",
    "\n",
    "model_prediction = model(sample_features)        # predicta outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True class              :', sample_class.item())\n",
    "print('Vår models predict      :', model_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bb457",
   "metadata": {},
   "source": [
    "Notera att, för vilken sample du än väljer, så spottar vår modell ut sig värden mellan 0 och 1! Sigmoid-aktiveringsfunktion säkerställer detta.\n",
    "\n",
    "\n",
    "Det kan kanske också se ut som att vår modell verkar predicta någorlunda bra so far, eftersom att både True outcome och våra predictions endast antar värden mellan 0 och 1 och således inte ligger så långt ifrån varandra - men alla våra predictions är helt random at this point, var så säkra. Testa själv med olika samples.Sannolikheterna vi spottar ur nonsens.\n",
    "\n",
    "Och det är ju inte så konstigt - för vi har ju inte tränat något än!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a42c62",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b19cb9",
   "metadata": {},
   "source": [
    "## Träna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4c32c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f2557",
   "metadata": {},
   "source": [
    "Observera att vi i koden nedan lagt till ytterliggare en sektion kod under vår epoch-loop. Denna ansvarar för att evaluera koden. \n",
    "\n",
    "Ignorera den för nu - du kommer få jobba med den strax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3                       \n",
    "batch_size = 16\n",
    "\n",
    "epochs = 10                    # antal loopar genom dataloader vi låter vår modell träna på vårt dataset.\n",
    "learning_rate = 0.5          # hur stora steg gradient descent tar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72031c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    initera modell, loss_function, optimizer & dataloader\n",
    "\n",
    "\n",
    "model = neuron(input_size)\n",
    "optimizer = SGD(model.parameters(), lr = learning_rate)\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                 \n",
    "                              batch_size = batch_size,       \n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    träna\n",
    "\n",
    "\n",
    "batch_losses = []\n",
    "evaluation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        \n",
    "        y_true = batch[1]\n",
    "        input_features = batch[0]\n",
    "        \n",
    "        y_pred=model(input_features)\n",
    "        loss=loss_function(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        batch_losses.append(batch_loss)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#   evalueringssektion \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = y_test\n",
    "    input_features = x_test\n",
    "    \n",
    "    y_pred = model(input_features)\n",
    "    loss = loss_function(y_pred, y_true)\n",
    "    \n",
    "    evaluation_loss = loss.item()\n",
    "    evaluation_losses.append(evaluation_loss)\n",
    "    \n",
    "        \n",
    "plt.plot(batch_losses, label='train loss')\n",
    "plt.plot(np.arange(1, epochs+1)*(len(train_dataloader)), evaluation_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.xlabel('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f48456",
   "metadata": {},
   "source": [
    "## Uppgifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fb6d4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da10c4c",
   "metadata": {},
   "source": [
    "**1)**\n",
    "\n",
    "Vi ska nu utforska sambandet mellan number of epochs och learning rate. Vi ska testa kombinationer av olika värden på dessa parametrar, och se hur det påverkar vår loss.\n",
    "\n",
    "Låt oss testa följande värden:\n",
    "\n",
    "epochs = [1,5,10,100,200]\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "Testa varje möjlig kombination av dessa värden, dvs\n",
    "\n",
    "    for epoch in epochs:\n",
    "    \n",
    "        for learning_rate in learning_rates:\n",
    "        \n",
    "            run training loop\n",
    "            plot(loss)\n",
    "        \n",
    "*Vad ser du för kurvor? Vad upptäcker du för samband? Does it make sense?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ee784",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566f85c",
   "metadata": {},
   "source": [
    "**2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655215b5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432be029",
   "metadata": {},
   "source": [
    "Testa nedan kodsnutt för ett antal olika sampels. Ser det bättre ut nu?\n",
    "\n",
    "**Varför tror du att logistisk regression kallas just regression, även fast vi använder det till klassificering?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d910f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 90                                     # välj här vilken sample som helst, ange värde mellan 0-899\n",
    "\n",
    "sample_features = x_test[sample]                # extrahera features\n",
    "sample_class = y_test[sample]                   # extrahera class (1 eller 0)\n",
    "\n",
    "model_prediction = model(sample_features)        # predicta outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f854e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True class              :', sample_class.item())\n",
    "print('Vår models predict      :', model_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d25fd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f4046",
   "metadata": {},
   "source": [
    "**2)**\n",
    "\n",
    "Fokusera nu på evalueringssektionen i vår träningskod. Säkerställ att du förstår vad som händer, steg för steg!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec5364",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a03ab",
   "metadata": {},
   "source": [
    "**3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f7733",
   "metadata": {},
   "source": [
    "Nu ska vi visualisera det vår evalueringssektion fångade upp. Ersätt de sista raderna kod (de som plottar) i träningsscellen med följande:\n",
    "\n",
    "________________________________________________________\n",
    "\n",
    "plt.plot(batch_losses, label='train loss')\n",
    "plt.plot(np.arange(1, epochs+1)*(len(train_dataloader)), evaluation_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.xlabel('batch')\n",
    "plt.show()\n",
    "________________________________________________________\n",
    "\n",
    "Testa nu att köra om din träningsloop för olika kombinationer av epoch och learning rate. \n",
    "\n",
    "Vad ser du? Does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1948d2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26540d72",
   "metadata": {},
   "source": [
    "**4**\n",
    "\n",
    "Gå tillbaks till början av vår notebook och försök att generera ett dataset som är svårare att klassificera, dvs ett där våra blobs inte går att separera like lätt. Du kan enkelt generera nya dataset genom att ändra på make_blobs-funktionens parameter random_state. \n",
    "\n",
    "Hitta ett värde på random_state som ger oss ett svårare dataset - träna sedan en ny modell (med olika värden på epoch och learning rate) och tolka det du ser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050000a2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
